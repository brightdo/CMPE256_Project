{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic, KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "from surprise.model_selection.split import train_test_split\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from surprise import dataset\n",
    "from surprise import get_dataset_dir\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in data & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('data/automotive.csv',delimiter=\",\")# read csv into ratings_df dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove duplicates( same uid + iid but different rating) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['reviewerID','asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we had to reduce the size drastically because of not enough computer memory( using hpc was a failure)\n",
    "df = df.iloc[:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two datasets; one for surprise library ( no unixReviewTime) and the other for my own time based knn (includes unixReviewTime)\n",
    "df_time = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up unused columns leaving only uid,iid,rating, and unix time for my use\n",
    "df_time = df_time.drop(['Unnamed: 0', 'reviewTime','style','verified'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up unused columns leaving only uid,iid,rating for surprise\n",
    "df = df.drop(['Unnamed: 0', 'reviewTime','style','verified','unixReviewTime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df_time.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change name and order of column for better readability\n",
    "df = df[['reviewerID','asin','overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time =df_time[['reviewerID','asin','overall','unixReviewTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['uid', 'iid','rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time.columns = ['uid', 'iid','rating','time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run dataset through reader to use it for surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))\n",
    "data=Dataset.load_from_df(df,reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and test(8:2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet, testSet = train_test_split(data, test_size=0.2, train_size=None, random_state=None, shuffle=True)\n",
    "#fulltrainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using user-based and similarity measure of cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name':'cosine','user_based':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run through knn basic algorithm (fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x7fe71d1104c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = KNNBasic( k = 3, sim_options = sim_options)\n",
    "algo.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions and rmse from library to compaer to our custom time-based knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9942284422080769"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions, verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my own algorithm encompassing time into finding better neighbor and estimate rating  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltrainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this knn algorithm from surprise will only be used to find neighbors of the testSet rows and not to predict ratings\n",
    "algo_custonknn = KNNBasic( k = 3, sim_options = sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x7fdfb946d6a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_custonknn.fit(fulltrainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start looking into neighbors and sorting result based on unix time and choosing top k neighbor to find average rating on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be the defualt global_mean used for predicted rating when finding estimate is not possible \n",
    "#(not enough neighbors have ratings for item we want to predict rating of). This is also how surprise deals with \n",
    "#ratings it is not able to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = trainingSet.global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPredictions=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(testSet)):\n",
    "#find inner id of user to use to retrieve its neighbors\n",
    "    uid = fulltrainset.to_inner_uid(testSet[i][0])\n",
    "    iid = testSet[i][1]\n",
    "    real_rating = testSet[i][2]\n",
    "    # retrieve inner id of users nearest to id\n",
    "    neighbors = algo_custonknn.get_neighbors(uid, k=(k+5))\n",
    "    neighbors_rawid =[]\n",
    "    # change inner neighbor id from surprise to raw id to be used by us \n",
    "    for id in neighbors:\n",
    "        neighbors_rawid.append(fulltrainset.to_raw_uid(id))\n",
    "    #new dataframe that only holds the k nearest neighbor's rating of corresponding item\n",
    "    temp = df_time.loc[df_time['uid'].isin(neighbors_rawid)]\n",
    "    temp = temp.loc[temp['iid'] == iid]\n",
    "    # if there is enough neighbors, we will find basic average to make our rating prediction\n",
    "    rating =0\n",
    "    if(len(temp)>=k):\n",
    "        for j in range(k):\n",
    "            rating += temp['rating'].values[j]\n",
    "        rating = rating/k\n",
    "    # if there is not enough neighbors to make a prediction, we use global average ( how surprise library does it)\n",
    "    else:\n",
    "        rating = default\n",
    "    #calculate square error of each prediction\n",
    "    rmse += ((real_rating - rating)**2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally compute rmse by finding mean and squaring it\n",
    "rmse= rmse/len(testSet)\n",
    "rmse = rmse**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0459295705729792\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
